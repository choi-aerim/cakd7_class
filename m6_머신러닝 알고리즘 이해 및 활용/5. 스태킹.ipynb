{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e1547b8",
   "metadata": {},
   "source": [
    "# 스태킹\n",
    "- 스태킹 앙상블 모델은 개별적인 기반 모델, 개별 기반 모델의 예측 데이터를 학습 데이터로 만들어서 학습하는 최종 메타 모델 두 종류의 모델이 필요함\n",
    "- 여러 개별 모델의 예측 데이터를 각각 스태킹 형태(X_test 예측 레이블의 병렬정렬)로 결합<br>\n",
    "    -> 최종 메타 모델의 학습용 피처 데이터 세트와 테스트용 피처 데이터 세트를 만드는 것\n",
    "    \n",
    "    \n",
    "- 많은 개별 모델이 필요하고, 스태킹을 적용한다고 해서 반드시 성능이 향상된다는 보장도 없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c43b4edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# 데이터 불러오기\n",
    "cancer_data = load_breast_cancer()\n",
    "\n",
    "X_data = cancer_data.data\n",
    "y_data = cancer_data.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b34a47ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
       "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
       "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
       "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
       "       'smoothness error', 'compactness error', 'concavity error',\n",
       "       'concave points error', 'symmetry error',\n",
       "       'fractal dimension error', 'worst radius', 'worst texture',\n",
       "       'worst perimeter', 'worst area', 'worst smoothness',\n",
       "       'worst compactness', 'worst concavity', 'worst concave points',\n",
       "       'worst symmetry', 'worst fractal dimension'], dtype='<U23')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer_data.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3af0de35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스태킹에 활용할 개별 머신러닝 모델 생성(KNN, RandomFoerest, DecisionTree, AdaBoost)\n",
    "\n",
    "knn_clf = KNeighborsClassifier(n_neighbors = 4)     # k의 개수, 근처의 개수\n",
    "rf_clf = RandomForestClassifier(n_estimators = 100, random_state = 0)\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "ada_clf = AdaBoostClassifier(n_estimators = 100)\n",
    "\n",
    "\n",
    "#스태킹으로 만들어진 데이터 세트 학습, 예측할 최종 모델\n",
    "## c: 규제 강도를 결정하는 파라미터\n",
    "lr_final = LogisticRegression(C = 10)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "507d5d6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>AdaBoostClassifier(n_estimators=100)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AdaBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>AdaBoostClassifier(n_estimators=100)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "AdaBoostClassifier(n_estimators=100)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 개별 모델 학습\n",
    "\n",
    "knn_clf.fit(X_train, y_train)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "dt_clf.fit(X_train, y_train)\n",
    "ada_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62443ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN 정확도: \n",
      " 0.9211\n",
      "\n",
      "RandomForest 정확도: \n",
      " 0.9649\n",
      "\n",
      "DecisionTree 정확도: \n",
      " 0.9123\n",
      "\n",
      "AdaBoost 정확도: \n",
      " 0.9561\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 학습된 개별 모델들의 예측 데이터셋 반환\n",
    "knn_pred  = knn_clf.predict(X_test)\n",
    "rf_pred  = rf_clf.predict(X_test)\n",
    "dt_pred  = dt_clf.predict(X_test)\n",
    "ada_pred  = ada_clf.predict(X_test)\n",
    "\n",
    "\n",
    "# 예측 정확도 측정\n",
    "print(f'KNN 정확도: \\n{accuracy_score(y_test, knn_pred): .4f}\\n')\n",
    "print(f'RandomForest 정확도: \\n{accuracy_score(y_test, rf_pred): .4f}\\n')\n",
    "print(f'DecisionTree 정확도: \\n{accuracy_score(y_test, dt_pred): .4f}\\n')\n",
    "print(f'AdaBoost 정확도: \\n{accuracy_score(y_test, ada_pred): .4f}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "59c3705d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 114)\n",
      "(114, 4)\n"
     ]
    }
   ],
   "source": [
    "# 개별 알고리즘으로부터 예측된 예측값을 피처 값으로 만들기\n",
    "\n",
    "## 배열화\n",
    "pred = np.array([knn_pred, rf_pred, dt_pred, ada_pred])\n",
    "print(pred.shape)\n",
    "\n",
    "\n",
    "## 전치행렬로 칼럼 레벨로 각 알고리즘의 예측 결과를 피처로 만듦\n",
    "pred = np.transpose(pred)\n",
    "print(pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5033f854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "로지스틱 회귀모델 정확도: 0.9737\n"
     ]
    }
   ],
   "source": [
    "# 예측 데이터로 생성된 데이터 세트를 기반으로 최종 메타 모델인 로지스틱 회귀 학습\n",
    "\n",
    "## 학습\n",
    "lr_final.fit(pred, y_test)\n",
    "\n",
    "## 예측\n",
    "final = lr_final.predict(pred)\n",
    "\n",
    "print(f'로지스틱 회귀모델 정확도: {accuracy_score(y_test, final):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131ffa8f",
   "metadata": {},
   "source": [
    "- 개별 모델의 예측 데이터를 스태킹으로 재구성해 최종 메타 모델에서 학습하고 예측한 결과, 정확도가 97.37%로 개별 모델 정확도보다 향상됨\n",
    "- <span style = 'background-color: #ffdce0'>스태킹 모델로 예측한다고해서 무조건 개별 모델보다 좋아지는 것은 아님</span>\n",
    "\n",
    "- 하지만 위와 같이 학습용 데이터가 아닌 테스트용 레이블 데이터를 기반으로 학습한 경우 <span style = 'background-color: #ffdce0'>과적합 문제</span> 발생할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa79c9c",
   "metadata": {},
   "source": [
    "# cv세트 기반 스태킹\n",
    "- <span style = 'background-color: #f1f8ff'>과적합을 개선하기 위해</span> 최종 메타 모델을 위한 데이터 세트를 만들 때 교차 검증 기반으로 예측된 결과 데이터 세트를 이용함\n",
    "\n",
    "- 개별 모델들이 교차 검증으로 메타 모델을 위한 학습용 스태킹 데이터 생성(cv개수 만큼 생성된 X_test예측 레이블 세트), "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53b1465",
   "metadata": {},
   "source": [
    "#### 과제1: cv세트 기반의 스태킹 앙상블 모델을 생성하고 평가하기(cv = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "292f4d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "# 최종 메타모델을 위한 학습/테스트 데이터를 생성하는 사용자 함수 생성\n",
    "\n",
    "## 분류 모델 객체, 원본 학습용 피처 데이터, 원본 학습용 레이블 데이터, 원본 테스트 피처 데이터, k폴드 개수를 인자로 받음\n",
    "def get_stacking_base_dataset(model, X_train_n, y_train_n, X_test_n, n_folds):\n",
    "    \n",
    "    # 지정된 n_folds로 KFold 생성\n",
    "    kf = KFold(n_splits = n_folds, shuffle = False)\n",
    "    \n",
    "    # 추후에 메타 모델이 사용할 학습 데이터 반환을 위해 넘파 배열 초기화\n",
    "    train_fold_pred = np.zeros((X_train_n.shape[0], 1))\n",
    "    test_pred = np.zeros((X_test_n.shape[0], n_folds))\n",
    "    \n",
    "    # 모델의 클래스 변수명 출력\n",
    "    print(model.__class__.__name__, 'model 시작')\n",
    "    \n",
    "    \n",
    "    \n",
    "    # k번째 폴드세트, 학습용 데이터 인덱스/검증용데이터 인덱스 지정\n",
    "    for folder_counter, (train_index, valid_index) in enumerate(kf.split(X_train_n)):\n",
    "        \n",
    "        # 입력된 학습 데이터에서 기반 모델이 학습/예측할 폴드 데이터 세트 출력\n",
    "        print('\\t 폴드 세트: ', folder_counter, '시작')\n",
    "        \n",
    "        X_tr = X_train_n[train_index]\n",
    "        y_tr = y_train_n[train_index]\n",
    "        x_te = X_train_n[valid_index]\n",
    "        \n",
    "        # 폴드 세트 내부에서 다시 만들어진 학습용, 검증용 데이터로 모델 학습 수행\n",
    "        model.fit(X_tr, y_tr)\n",
    "        \n",
    "        # 폴드 세트 내부에서 다시 만들어진 검증용 데이터로 예측\n",
    "        train_fold_pred[valid_index, : ] = model.predict(x_te).reshape(-1,1)\n",
    "        \n",
    "        # 입력된 원본 테스트 데이터를 폴드 세트 내 학습된 모델에서 예측 후 데이터 저장\n",
    "        test_pred[ : , folder_counter] = model.predict(X_test_n)\n",
    "        \n",
    "        \n",
    "    # 폴드 세트 내에서 원본 테스트 데이터를 예측한 데이터를 평균하여 테스트 데이터로 생성\n",
    "    test_pred_mean = np.mean(test_pred, axis = 1).reshape(-1,1)\n",
    "    \n",
    "    \n",
    "    # train_fold_pred는 최종 메타 모델이 사용하는 학습 데이터, test_pred_mean은 테스트 데이터\n",
    "    return train_fold_pred, test_pred_mean\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "aae327ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier model 시작\n",
      "\t 폴드 세트:  0 시작\n",
      "\t 폴드 세트:  1 시작\n",
      "\t 폴드 세트:  2 시작\n",
      "\t 폴드 세트:  3 시작\n",
      "\t 폴드 세트:  4 시작\n",
      "\t 폴드 세트:  5 시작\n",
      "\t 폴드 세트:  6 시작\n",
      "RandomForestClassifier model 시작\n",
      "\t 폴드 세트:  0 시작\n",
      "\t 폴드 세트:  1 시작\n",
      "\t 폴드 세트:  2 시작\n",
      "\t 폴드 세트:  3 시작\n",
      "\t 폴드 세트:  4 시작\n",
      "\t 폴드 세트:  5 시작\n",
      "\t 폴드 세트:  6 시작\n",
      "DecisionTreeClassifier model 시작\n",
      "\t 폴드 세트:  0 시작\n",
      "\t 폴드 세트:  1 시작\n",
      "\t 폴드 세트:  2 시작\n",
      "\t 폴드 세트:  3 시작\n",
      "\t 폴드 세트:  4 시작\n",
      "\t 폴드 세트:  5 시작\n",
      "\t 폴드 세트:  6 시작\n",
      "AdaBoostClassifier model 시작\n",
      "\t 폴드 세트:  0 시작\n",
      "\t 폴드 세트:  1 시작\n",
      "\t 폴드 세트:  2 시작\n",
      "\t 폴드 세트:  3 시작\n",
      "\t 폴드 세트:  4 시작\n",
      "\t 폴드 세트:  5 시작\n",
      "\t 폴드 세트:  6 시작\n"
     ]
    }
   ],
   "source": [
    "# 여러 분류 모델별로 stack_base_model()함수 수행\n",
    "\n",
    "knn_train, knn_test = get_stacking_base_dataset(knn_clf, X_train, y_train, X_test, 7)\n",
    "rf_train, rf_test = get_stacking_base_dataset(rf_clf, X_train, y_train, X_test, 7)\n",
    "dt_train, dt_test = get_stacking_base_dataset(dt_clf, X_train, y_train, X_test, 7)\n",
    "ada_train, ada_test = get_stacking_base_dataset(ada_clf, X_train, y_train, X_test, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a003d9f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 학습 피처 데이터: (455, 30),  원본 테스트 피처데이터: (114, 30)\n",
      "스태킹 학습 피처 데이터 Shape: (455, 4), 스태킹 테스트 피처 데이터 Shape: (114, 4)\n"
     ]
    }
   ],
   "source": [
    "stack_final_X_train = np.concatenate((knn_train, rf_train, dt_train, ada_train), axis = 1)\n",
    "stack_final_X_test = np.concatenate((knn_test, rf_test, dt_test, ada_test), axis = 1)\n",
    "\n",
    "print(f'원본 학습 피처 데이터: {X_train.shape},  원본 테스트 피처데이터: {X_test.shape}')\n",
    "print(f'스태킹 학습 피처 데이터 Shape: {stack_final_X_train.shape}, 스태킹 테스트 피처 데이터 Shape: {stack_final_X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "13b444e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 메타 모델의 예측 정확도: 0.9737\n"
     ]
    }
   ],
   "source": [
    "# 스태킹 피처 데이터로 학습\n",
    "lr_final.fit(stack_final_X_train, y_train)\n",
    "\n",
    "# 스태킹 테스트 피처 데이터로 예측\n",
    "stack_final = lr_final.predict(stack_final_X_test)\n",
    "\n",
    "# 원본 y_test 데이터와 정확도 평가\n",
    "print(f'최종 메타 모델의 예측 정확도: {accuracy_score(y_test, stack_final):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5c2689",
   "metadata": {},
   "source": [
    "- 최종 메타 모델의 예측 정확도는 약 97.37%\n",
    "\n",
    "\n",
    "- 원래, 스태킹을 이루는 모델은 최적으로 파라미터를 튜닝한 상태에서 스태킹 모델을 만드는 것이 일반적임\n",
    "- 스태킹 모델은 분류 뿐만 아니라 회귀에서도 적용이 가능함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc7819e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fcf96a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7a96c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2953437c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a3334d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "186.475px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
