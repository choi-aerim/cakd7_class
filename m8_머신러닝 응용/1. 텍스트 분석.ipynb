{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33de5827",
   "metadata": {},
   "source": [
    "# 텍스트분석"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6cc06bf",
   "metadata": {},
   "source": [
    "## 클렌징"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44058de",
   "metadata": {},
   "source": [
    "## 텍스트 토큰화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93dfa392",
   "metadata": {},
   "source": [
    "### 문장 토큰화\n",
    "- 문장의 마침표, 개행문자 등 문장의 마지막을 뜻하는 기호에 따라 분리하는 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6197c0eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import sent_tokenize\n",
    "import nltk\n",
    "\n",
    "# 마침표, 개행문자 등 데이터 세트 다운로드\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41d6467b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " sent_tokenize 객체 타입: \n",
      "<class 'list'>,\n",
      "\n",
      " 문장 개수:3\n",
      "\n",
      " 출력: \n",
      "['The Matrix is everywhere its all around us, here even in this room.', 'You can see it out your window or on your television.', 'You feel it when you go to work, or go to church or pay your taxes.']\n"
     ]
    }
   ],
   "source": [
    "text_sample = 'The Matrix is everywhere its all around us, here even in this room. \\\n",
    "               You can see it out your window or on your television. \\\n",
    "               You feel it when you go to work, or go to church or pay your taxes.'\n",
    "\n",
    "sentences = sent_tokenize(text = text_sample)\n",
    "\n",
    "print(f' sent_tokenize 객체 타입: \\n{type(sentences)},\\n\\n 문장 개수:{len(sentences)}\\n')\n",
    "print(f' 출력: \\n{sentences}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab04f76",
   "metadata": {},
   "source": [
    "### 단어 토큰화\n",
    "- 문장을 단어로 토큰화\n",
    "- 공백, 쉼포, 마침표, 개행문자 등으로 단어를 분리 혹은 정규표현식을 이용해 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9de0b763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " word_tokenize 객체 타입: \n",
      "<class 'list'>,\n",
      "\n",
      " 단어 개수:15\n",
      "\n",
      " 출력: \n",
      "['The', 'Matrix', 'is', 'everywhere', 'its', 'all', 'around', 'us', ',', 'here', 'even', 'in', 'this', 'room', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk import word_tokenize\n",
    "\n",
    "sentence = sentences[0]\n",
    "\n",
    "words = word_tokenize(sentence)\n",
    "\n",
    "print(f' word_tokenize 객체 타입: \\n{type(words)},\\n\\n 단어 개수:{len(words)}\\n')\n",
    "print(f' 출력: \\n{words}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596e5355",
   "metadata": {},
   "source": [
    "### 문장 및 단어 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "794a5fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " word_tokenize 객체 타입: \n",
      "<class 'list'>,\n",
      "\n",
      " 단어 개수:3\n",
      "\n",
      " 출력:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['The',\n",
       "  'Matrix',\n",
       "  'is',\n",
       "  'everywhere',\n",
       "  'its',\n",
       "  'all',\n",
       "  'around',\n",
       "  'us',\n",
       "  ',',\n",
       "  'here',\n",
       "  'even',\n",
       "  'in',\n",
       "  'this',\n",
       "  'room',\n",
       "  '.'],\n",
       " ['You',\n",
       "  'can',\n",
       "  'see',\n",
       "  'it',\n",
       "  'out',\n",
       "  'your',\n",
       "  'window',\n",
       "  'or',\n",
       "  'on',\n",
       "  'your',\n",
       "  'television',\n",
       "  '.'],\n",
       " ['You',\n",
       "  'feel',\n",
       "  'it',\n",
       "  'when',\n",
       "  'you',\n",
       "  'go',\n",
       "  'to',\n",
       "  'work',\n",
       "  ',',\n",
       "  'or',\n",
       "  'go',\n",
       "  'to',\n",
       "  'church',\n",
       "  'or',\n",
       "  'pay',\n",
       "  'your',\n",
       "  'taxes',\n",
       "  '.']]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import sent_tokenize, word_tokenize\n",
    "\n",
    "# 여러 개의 문장으로 된 입력 데이터를 문장별로 단어 토큰화하도록 만드는 사용자 함수 생성\n",
    "def tokenize_text(text):\n",
    "    ## 문장 토큰화\n",
    "    sentences = sent_tokenize(text)\n",
    "    \n",
    "    ## 문장별 단어 토큰화\n",
    "    word_tokens = [word_tokenize(sentence) for sentence in sentences]\n",
    "    \n",
    "    return word_tokens\n",
    "\n",
    "# 수행\n",
    "word_tokens = tokenize_text(text_sample)\n",
    "print(f' word_tokenize 객체 타입: \\n{type(word_tokens)},\\n\\n 단어 개수:{len(word_tokens)}\\n')\n",
    "print(f' 출력:')\n",
    "word_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28a4453",
   "metadata": {},
   "source": [
    "### n_gram\n",
    "- 연속된 n개의 단어를 하나의 토큰화 단위로 분리해 내는 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec783b57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "916081bf",
   "metadata": {},
   "source": [
    "## 스톱워드 제거\n",
    "- 문장을 구성하는 필수 문법 요소지만 문맥적으로 큰 의미가 없는 단어를 사전에 제거\n",
    "- 빈번하게 텍스트에 나타나면 중요 단어로 인지될 수 있기 때문에 중요한 작업임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c6bb89b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "# 스톱워드 목록 다운로드\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "19c5ec9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "스톱워드 리스트 내 단어 개수:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('스톱워드 리스트 내 단어 개수:')\n",
    "len(nltk.corpus.stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d9597555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "스톱워드 리스트:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('스톱워드 리스트:')\n",
    "nltk.corpus.stopwords.words('english')[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "89a63db1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['matrix', 'everywhere', 'around', 'us', ',', 'even', 'room', '.'],\n",
       " ['see', 'window', 'television', '.'],\n",
       " ['feel', 'go', 'work', ',', 'go', 'church', 'pay', 'taxes', '.']]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "# 스톱워드 리스트 생성\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "\n",
    "all_tokens = []\n",
    "for sentence in word_tokens:\n",
    "    \n",
    "    filtered_words = []\n",
    "    for word in sentence:\n",
    "        # 소문자로 변환\n",
    "        word = word.lower()\n",
    "        # 토큰화된 개별 단어가 스톱워드 리스트에 포함되지 않으면 리스트에 담기\n",
    "        if word not in stopwords:\n",
    "            filtered_words.append(word)\n",
    "        # 문장별 걸러진 단어를 최종 리스트에 담기    \n",
    "    all_tokens.append(filtered_words)\n",
    "        \n",
    "all_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e622298",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1435fb22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccec003",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
